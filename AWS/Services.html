<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>(AWS)Services</title>
    <link rel="website icon" href="/Amazon_icon.png">
    <style>
        body{
            background-image: url(/wallpaperflare.com_wallpaper\ \(1\).jpg);
            background-repeat: no-repeat;
            background-size: cover;
            background-attachment: fixed;

        }
        img{
            height: 100px;
            width: 100px;
            margin-left: 1700px;
        }
        fieldset{
            border-radius: 50px;
            /* text-align: center; */
            color: black;
            font-weight: bolder;
            font-weight: bolder;
            font-style: italic;
            padding-left: 50px;
            /* font-style: oblique; */
        width: 1820px;
        height:1000px;
        font-weight: bolder;
        }
        h1{
            background-color: aliceblue;
           border-radius: 10px;
           width: 200px;
           margin-left: 100px;
        }
        summary{
          font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        p{
            font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            word-spacing: 2px;
        }
      h1:hover{
        transform: scale3d(2,2,2);
      }
    </style>
</head>
<body>
    <a href="/AWS_Web_site_13_assinment_3.html" target="_blank">
        <img src="HOME.png"alt="">
    </a>
    
    <h1>Service :- </h1>
    <fieldset>  
        <details>
            <summary>Analytics</summary>
            <p>Amazon OpenSearch Service
                Securely unlock real-time search, monitoring, and analysis of business and operational data
                Up to 750 hours per month
                on t2 and t3 small.search instances with the AWS Free Tier
                Increase operational excellence by using a popular open source solution, managed by AWS.
                Audit and secure your data with a data center and network architecture with built-in certifications.
                Systematically detect potential threats and react to a system’s state through machine learning, alerting, and visualization.
                Optimize time and resources for strategic work
                How it works
                Amazon OpenSearch Service makes it easy for you to perform interactive log analytics, real-time application monitoring, website search, and more. OpenSearch is an open source, distributed search and analytics suite derived from Elasticsearch. Amazon OpenSearch Service offers the latest versions of OpenSearch, support for 19 versions of Elasticsearch (1.5 to 7.10 versions), as well as visualization capabilities powered by OpenSearch Dashboards and Kibana (1.5 to 7.10 versions). Amazon OpenSearch Service currently has tens of thousands of active customers with hundreds of thousands of clusters under management processing hundreds of trillions of requests per month.
                How Amazon OpenSearch works
                
                
                Introduction to Amazon OpenSearch Service (1:41)
                Introduction to Amazon OpenSearch Service
                Amazon OpenSearch Service securely unlocks real-time search, monitoring, and analysis of business and operational data for use cases like application monitoring, log analytics, observability, and website search.</p>
        </details>  
   <details>
    <summary>Cloud Finacial management</summary>
    <p>AWS Budgets
        Improve planning and cost control with flexible budgeting and forecasting
        
        Track your costs, usage, and coverage with custom budgets.
        
        Stay informed on forecasted spend and resource use.
        
        Create custom actions to prevent overages, inefficient resource use, or lack of coverage.
        
        How it works
        With AWS Budgets, set custom budgets to track your costs and usage, and respond quickly to alerts received from email or SNS notifications if you exceed your threshold.
        
        Diagram shows how AWS Budgets can help users with budget planning and forecasting through budget creation, alerts, and automated responses.
        Enlarge and read image description
        Use cases
        Monitor costs and usage
        Set your preferred budget period to daily, monthly, quarterly, or annually, and create specific budget limits.
        
        Learn more about best practices »
        Create scheduled reports
        Stay informed on how actual or forecasted costs and usage progress toward your budget threshold.
        
        Learn more about creating a budget report »
        Respond to thresholds
        Set up custom actions to run automatically or through an approval process when a budget target is exceeded.
        
        Learn more about creating alerts »
        How to get started
        Check out product features
        Dive deeper into cost management and optimization.
        
        Learn more »
        Control your AWS costs
        Learn how to manage costs using the AWS Free Tier and AWS Budgets.
        
        Explore the getting started guide »
        Create and manage budgets
        Set custom budgets that alert you when you exceed your budgeted thresholds.
        
        Get started »</p>
   </details>
   <details>
    <summary>Compute</summary>
    <p>Amazon EC2 features
        Amazon EC2 provides the broadest and deepest instance choice to match your workload’s needs. General purpose, compute optimized, memory optimized, storage optimized, and accelerated computing instance types are available that provide the optimal compute, memory, storage, and networking balance for your workloads. Processors from Intel, AMD, NVIDIA and AWS power these instance types and provide additional performance and cost optimizations. Local storage and enhanced networking options available with instance types further help optimize performance for workloads that are disk or network I/O bound. Many instance types also offer bare metal instances that provide your applications with direct access to the processor and memory of the underlying server for running in non-virtualized environments or for applications where you want to use your own hypervisor. To find the right instance for your workload, visit the EC2 instance types page. You can also use the AWS Compute Optimizer to get recommendations on optimal AWS Compute resources for your workloads to reduce costs and improve performance.
        
        Global Infrastructure
        Multiple Locations
        Amazon EC2 provides the ability to place instances in multiple locations. Amazon EC2 locations are composed of Regions and Availability Zones. Availability Zones are distinct locations that are engineered to be insulated from failures in other Availability Zones and provide inexpensive, low latency network connectivity to other Availability Zones in the same Region. By launching instances in separate Availability Zones, you can protect your applications from failure of a single location. Regions consist of one or more Availability Zones and are geographically dispersed. The Amazon EC2 Service Level Agreement commitment is 99.99% availability for each Amazon EC2 Region. Please refer to Regional Products and Services for more details of our product and service availability by region.
        High Precision Time with Amazon Time Sync Service
        The Amazon Time Sync Service provides a highly accurate, reliable and available time source to AWS services including EC2 instances. For instructions on how to access the service, see Setting the Time sections of the Linux and Windows User Guides.
        Choice of operating systems and software
        Amazon Machine Images (AMIs) are preconfigured with an ever-growing list of operating systems, including Microsoft Windows and Linux distributions such as Amazon Linux 2, Ubuntu, Red Hat Enterprise Linux, CentOS, SUSE and Debian. We work with our partners and community to provide you with the most choice possible. The AWS Marketplace features a wide selection of commercial and free software from well-known vendors, designed to run on your EC2 instances.
        Cost and Capacity Optimization
        Pay for What You Use
        With per-second billing, you only pay for what you use. It takes the cost of unused minutes and seconds in an hour off of the bill, so you can focus on improving your applications instead of maximizing usage to the hour. Learn more about EC2 pricing.
        Scale Seamlessly with Amazon EC2 Auto Scaling
        Amazon EC2 Auto Scaling allows you to automatically scale your Amazon EC2 capacity up or down according to conditions you define. You can use the dynamic and predictive scaling policies within EC2 Auto Scaling to add or remove EC2 instances. Predictive scaling uses machine learning to proactively allocate instances based on anticipated demand, and dynamic scaling allows you to scale compute based on defined metrics. With EC2 Auto Scaling, you can ensure that the number of Amazon EC2 instances you’re using scales up seamlessly during demand spikes to maintain performance, and scales down automatically during demand lulls to minimize costs. See Amazon EC2 Auto Scaling for more details.
        Optimize Compute Performance and Cost with Amazon EC2 Fleet
        With a single API call, Amazon EC2 Fleet lets you provision compute capacity across EC2 instance types, Availability Zones, and purchase models to help optimize scale, performance and cost. Read FAQs and this AWS blog to learn more. You can also access EC2 Fleet capabilities via Amazon EC2 Auto Scaling to provision and automatically scale compute capacity across EC2 instance types, Availability Zones, and purchase options in a single Auto Scaling Group. Learn more »
        Optimized CPU Configurations
        The Optimize CPUs feature gives you greater control of your Amazon EC2 instances on two fronts. First, you can specify a custom number of vCPUs when launching new instances to save on vCPU-based licensing costs. Second, you can disable Intel Hyper-Threading Technology (Intel HT Technology) for workloads that perform well with single-threaded CPUs, such as certain high-performance computing (HPC) applications. To learn more about how Optimize CPUs can help you, visit the Optimize CPUs documentation here.
        Pause and Resume Your Instances
        You can hibernate your Amazon EC2 instances backed by Amazon EBS, and resume them from this state at a later time. Applications that take a while to bootstrap and persist state into memory (RAM) can benefit from this feature. For more information about hibernation, and supported instance types and operating systems, visit the FAQs.
        Storage
        Optimal storage for every workload
        Different Amazon EC2 workloads can have vastly different storage requirements. Beyond the built-in instance storage, we also offer Amazon Elastic Block Store (Amazon EBS) and Amazon Elastic File System (Amazon EFS) to suit other cloud storage workload requirements. Amazon EBS provides persistent, highly available, consistent, low-latency block storage volumes for use with Amazon EC2 instances, while Amazon EFS provides simple, scalable, persistent, fully managed cloud file storage for shared access.
        Networking
        High Packet-Per-Second Performance and Low Latency with Enhanced Networking
        Enhanced Networking enables you to get significantly higher packet per second (PPS) performance, lower network jitter and lower latencies. This feature uses a network virtualization stack that provides higher I/O performance and lower CPU utilization compared to traditional implementations. For instructions on how to enable Enhanced Networking on EC2 instances, see the Enhanced Networking on Linux and Enhanced Networking on Windows tutorials. For availability of this feature by instance, or to learn more, visit the Enhanced Networking FAQ section.
        Run High Levels of Inter-Node Communications with Elastic Fabric Adapter
        Elastic Fabric Adapter (EFA) is a network interface for Amazon EC2 instances that enables customers to run applications requiring high levels of inter-instance communications, like machine learning, computational fluid dynamics, weather modeling, and reservoir simulation, at scale on AWS. EFA is available as an optional EC2 networking feature that you can enable on any supported EC2 instance at no additional cost. Learn more.
        Manage Dynamic Cloud Computing Services with Elastic IP Addresses
        Elastic IP addresses are static IP addresses designed for dynamic cloud computing. An Elastic IP address is associated with your account, not with a particular instance, and you control that address until you choose to explicitly release it. Unlike traditional static IP addresses, however, Elastic IP addresses allow you to mask instance or Availability Zone failures by programmatically remapping your public IP addresses to any instance in your account. You can also optionally configure the reverse DNS record of any of your Elastic IP addresses by filling out this form.
        High Throughput and Low Latency with High Performance Computing (HPC) Clusters
        Customers with complex computational workloads such as tightly coupled parallel processes, or with applications sensitive to network performance, can achieve the same high compute and network performance provided by custom-built infrastructure while benefiting from the elasticity, flexibility and cost advantages of Amazon EC2. Cluster Compute, Cluster GPU, and High Memory Cluster instances have been specifically engineered to provide high-performance network capability and can be programmatically launched into clusters – allowing applications to get the low-latency network performance required for tightly coupled, node-to-node communication. Cluster instances also provide significantly increased throughput making them well suited for customer applications that need to perform network-intensive operations. Learn more about how Amazon EC2 and other AWS services can be used for HPC Applications.
        Access Services Hosted on AWS Easily and Securely with AWS PrivateLink
        AWS PrivateLink is a purpose-built technology designed for customers to access Amazon services in a highly performant and highly available manner, while keeping all the network traffic within the AWS network. Learn more about AWS PrivateLink.
        
        Operating Systems and Software
        Amazon Machine Images (AMIs) are preconfigured with an ever-growing list of operating systems, including Microsoft Windows and Linux distributions such as Amazon Linux 2, Ubuntu, Red Hat Enterprise Linux, CentOS, SUSE and Debian. We work with our partners and community to provide you with the most choice possible. The AWS Marketplace features a wide selection of commercial and free software from well-known vendors, designed to run on your EC2 instances.
        Maintenance
        AWS regularly performs routine hardware, software, power, and network maintenance with minimal disruption across all EC2 instance types. This is achieved by a combination of technologies and methods across the entire AWS Global infrastructure, such as live update and live migration as well as redundant and concurrently maintainable systems. Non-intrusive maintenance technologies such as live update and live migration do not require instances to be stopped or rebooted. Customers are not required to take any action prior to, during or after live migration or live update. These technologies help improve application uptime and reduce your operational effort. Amazon EC2 uses live update to deploy software to servers quickly with minimal impact to customer instances. Live update ensures that customers’ workloads run on servers with software that is up-to-date with security patches, new instance features and performance improvements. Amazon EC2 uses live migration when running instances need to be moved from one server to another for hardware maintenance or to optimize placement of instances or to dynamically manage CPU resources. Amazon EC2 has been expanding the scope and coverage of non-intrusive maintenance technologies over the years so that scheduled maintenance events are a fallback option rather than the primary means of enabling routine maintenance.</p>
   </details>
  
    <details>
        <summary>containers</summary>
        <p>mazon container orchestrator integration
            Amazon Elastic Container Registry (Amazon ECR) is integrated with Amazon Elastic Container Service (Amazon ECS) and Amazon Elastic Kubernetes Service (Amazon EKS), which means you can easily store and run container images for applications with either orchestrator. All you need to do is specify the Amazon ECR repository in your task or pod definition for Amazon ECS or Amazon EKS to retrieve the appropriate images for your applications.
            OCI and Docker support
            Amazon ECR supports Open Container Initiative (OCI) standards and the Docker Registry HTTP API V2. This allows you to use Docker CLI commands (e.g., push, pull, list, tag) or your preferred Docker tools to interact with Amazon ECR, maintaining your existing development workflow. You can easily access Amazon ECR from any Docker environment, whether in the cloud, on-premises, or on your local machine. Amazon ECR lets you store Docker container images and related OCI artifacts in your repositories.
            Public container image and artifact gallery
            You can discover and use container software that vendors, open source projects, and community developers share publicly in the Amazon ECR public gallery. Popular base images such as operating systems, AWS-published images, Kubernetes add-ons, and files, such as Helm charts, can be found in the gallery. You don’t need to use an AWS account to search or pull a public image; however, using your account makes it easier and faster to use public container software.
            AWS Marketplace
            Amazon ECR stores both the containers you create and any container software you buy through AWS Marketplace. AWS Marketplace for Containers offers verified container software for high performance computing, security, and developer tools, as well as software as a service (SaaS) products that manage, analyze, and protect container applications.
            
            High availability and durability
            Amazon ECR stores your container images and artifacts in Amazon Simple Storage Service (S3). Amazon S3 is designed for 99.999999999% (11 9’s) of data durability because it automatically creates and stores copies of all S3 objects across multiple systems. This means that your data is available when needed and protected against failures, errors, and threats. Amazon ECR can also automatically replicate your data to multiple AWS Regions for your high availability applications.
            Team and public collaboration
            Amazon ECR supports the ability to define and organize repositories in your registry using namespaces. This allows you to organize your repositories based on your team’s existing workflows. You can set which API actions another user may perform on your repository (e.g., create, list, describe, delete, and get) through resource-level policies, allowing you to share your repositories easily with different users and AWS accounts. You can easily share your container artifacts with anyone in the world by storing them in a public repository.
            Access control
            Amazon ECR uses AWS Identity and Access Management (IAM) to control and monitor who and what (e.g., EC2 instances) can access your container images. Through IAM, you can define policies to allow users within the same AWS account or other accounts to access your container images in private repositories. You can also further refine these policies by specifying different permissions for different users and roles (e.g., push, pull, or full administrator access). Anyone in the world can access your container images stored in public repositories for worldwide collaboration.
            Encryption
            You can transfer your container images to and from Amazon ECR via HTTPS. Your images are also automatically encrypted at rest using Amazon S3 server-side encryption. Amazon ECR also lets you choose your own key managed by AWS Key Management Service (AWS KMS) to encrypt images at rest.
            Third-party integrations
            Amazon ECR is integrated with third-party developer tools. You can integrate Amazon ECR into your continuous integration and delivery process, allowing you to maintain your existing development workflow. Learn more about our third-party integration on our Partners page.
            Pull through cache repositories
            With Amazon ECR’s pull through cache repositories, you can retrieve, store, and sync container artifacts stored in publicly accessible container registries. They offer the high download rates that you need and the availability, security, and scale that you’ve come to depend on. With frequent registry syncs and no additional tools to manage, pull through cache repositories help you keep container images sourced from public registries up to date.</p>
    </details>
    <details>
        <summary>DataBase</summary>
        <p>Amazon DynamoDB is a NoSQL database that supports key-value and document data models. Developers can use DynamoDB to build modern, serverless applications that can start small and scale globally to support petabytes of data and tens of millions of read and write requests per second. DynamoDB is designed to run high-performance, internet-scale applications that would overburden traditional relational databases.
            What's new:
            
            Create data schemas and tables in DynamoDB using sample data model templates and datasets available in NoSQL Workbench.
            NoSQL Workbench now bundles with DynamoDB Local to help you set up a local DynamoDB design and development environment to get started faster.
            Import data from Amazon S3 directly into a new DynamoDB table without writing any code or managing additional infrastructure.
            AWS Glue supports DynamoDB as a source to combine and replicate data continuously across multiple databases in near real-time.
            Use PartiQL, a SQL-compatible query language, to query, insert, update, and delete table data in DynamoDB.
            Use Amazon Kinesis Data Streams to capture item-level changes in your DynamoDB tables.
            Restore DynamoDB tables even faster.
            AWS Pricing Calculator now supports DynamoDB.
            Export data from DynamoDB to Amazon Simple Storage Service (Amazon S3) and use other AWS services such as Amazon Athena to analyze your data and extract actionable insights.</p>
    </details>
   <details>
    <summary>Front-end Web & Mobile</summary>
    <p>Amazon API Gateway Features

        Amazon API Gateway is a fully managed service that makes it easy for developers to publish, maintain, monitor, secure, and operate APIs at any scale. It's a pay-as-you-go service that takes care of all of the undifferentiated heavy lifting involved in securely and reliably running APIs at scale.
        
        With the proliferation of mobile devices and the rise of the Internet of Things (IoT), it is increasingly common to make backend systems and data accessible to applications through APIs. Because so many applications use these APIs and communities of developers rely on them, an increasing amount of time and effort is spent on API development and API management. To make it easy for you to use these APIs, API Gateway can generate client SDKs for a number of languages, including JavaScript, iOS, and Android.
        Support for RESTful APIs and WebSocket APIs
        With API Gateway, you can create RESTful APIs using either HTTP APIs or REST APIs. HTTP APIs are the best way to build APIs that do not require API management features. HTTP APIs are optimized for serverless workloads and HTTP backends—they offer up to 71% cost savings and 60% latency reduction compared to REST APIs from API Gateway. For workloads that require API proxy functionality and API management features in a single solution, such as usage plans and API keys, API Gateway offers REST APIs. To see a side-by-side comparison of supported features for HTTP APIs and REST APIs, visit our documentation. To build real-time two-way communication applications, such as chat apps and streaming dashboards, use WebSocket APIs. To learn more about RESTful APIs and WebSocket APIs from API Gateway, visit our FAQ page.
        Private integrations with AWS ELB & AWS Cloud Map
        With API Gateway, you can route requests to private resources in your VPC. Using HTTP APIs, you can build APIs for services behind private ALBs, private NLBs, and IP-based services registered in AWS Cloud Map, such as ECS tasks.
        Resiliency
        API Gateway helps you manage traffic to your backend systems by allowing you to set throttling rules based on the number of requests per second for each HTTP method in your APIs. API Gateway handles any level of traffic received by an API, so you are free to focus on your business logic and services rather than maintaining infrastructure. If you’re using REST APIs, you can also set up a cache with customizable keys and time-to-live in seconds for your API data to avoid hitting your backend services for each request.
        Easy API Creation and Deployment
        With API Gateway, you can quickly and easily create a custom API to your code running in AWS Lambda and then call the Lambda code from your API. API Gateway can execute AWS Lambda code in your account, start AWS Step Functions state machines, or make calls to AWS Elastic Beanstalk, Amazon EC2, or web services outside of AWS with publicly accessible HTTP endpoints. Using the API Gateway console, you can define your REST API and its associated resources and methods, manage your API lifecycle, generate your client SDKs, and view API metrics.
        API Operations Monitoring
        After an API is deployed and in use, API Gateway provides you with a dashboard to visually monitor calls to the services. The API Gateway console is integrated with Amazon CloudWatch, so you get backend performance metrics such as API calls, latency, and error rates. Because API Gateway uses CloudWatch to record monitoring information, you can set up custom alarms on API Gateway APIs. API Gateway can also log API execution errors to CloudWatch Logs to make debugging easier.
        AWS Authorization
        To authorize and verify API requests to AWS services, API Gateway can help you leverage signature version 4 for REST APIs and WebSocket APIs. Using signature version 4 authentication, you can use AWS Identity and Access Management (IAM) and access policies to authorize access to your APIs and all your other AWS resources. You can also use AWS Lambda functions to verify and authorize bearer tokens such as JWT tokens or SAML assertions.
        API Keys for Third-Party Developers
        If you’re using REST APIs, API Gateway helps you manage the ecosystem of third-party developers accessing your APIs. You can create API keys on API Gateway, set fine-grained access permissions on each API key, and distribute them to third-party developers to access your APIs. You can also define plans that set throttling and request quota limits for each individual API key. The use of API keys is completely optional and must be enabled on a per-method level.
        SDK Generation
        If you’re using REST APIs, API Gateway can generate client SDKs for a number of platforms which you can use to quickly test new APIs from your applications and distribute SDKs to third-party developers. The generated SDKs handle API keys and sign requests using AWS credentials. API Gateway can generate client SDKs for Java, JavaScript, Java for Android, Objective-C or Swift for iOS, and Ruby. You can use AWS CLI to generate and download an SDK of an API for a supported platform by calling the get-sdk command.
        API Lifecycle Management
        If you're using REST APIs, API Gateway lets you run multiple versions of the same API simultaneously so that applications can continue to call previous API versions even after the latest versions are published. API Gateway also helps you manage multiple release stages for each API version, such as alpha, beta, and production. Each API stage can be configured to interact with different backend endpoints based on your API setup. Specific stages and versions of an API can be associated with a custom domain name and managed through API Gateway. Stage and version management allow you to easily test new API versions that enhance or add new functionality to earlier API releases, and ensures backward-compatibility as user communities transition to adopt the latest release.</p>
   </details>
  <details>
    <summary>Internet Of Things</summary>
    <p>AWS IoT Greengrass Features
        AWS IoT Greengrass recently announced a major version release. You can learn more about the new features in our documentation.
        
        
        Local processing
        Local processing for AWS Lambda
        AWS IoT Greengrass includes support for AWS Lambda. With AWS IoT Greengrass, you can run AWS Lambda functions on the device to respond quickly to local events, interact with local resources, and process data to minimize the cost of transmitting data to the cloud.
        
        Local support for containers
        You can deploy, run, and manage Docker containers on AWS IoT Greengrass devices. Your Docker images can be stored in Docker container registries, such as Amazon Elastic Container Registry (Amazon ECR), Docker Hub, or private Docker Trusted Registries (DTRs).
        Local support for AWS IoT Device Shadows
        AWS IoT Greengrass also includes the functionality of AWS IoT Device Shadows. The Device Shadow caches the state of your device, like a virtual version or “shadow,” of each device that tracks the device’s current versus desired state and synchronizes that state with the cloud when connectivity is available.
        
        Local messaging
        AWS IoT Greengrass enables messaging between the AWS IoT Greengrass Core and devices using the AWS IoT Device SDK on a local network, facilitating communication even when there is no connection to AWS. With AWS IoT Greengrass, your devices can process messages and deliver them to another device or to the cloud based on business rules you define.
        
        Local resource access
        AWS Lambda functions deployed on an AWS IoT Greengrass Core can access local resources that are attached to the device. This allows you to use serial ports, peripherals such as add-on security devices, sensors and actuators, on-board GPUs, or the local file system to quickly access and process local data.
        
        Local development
        AWS IoT Greengrass lets you rapidly develop and debug code on a test device before using the cloud to deploy to your production devices. You can use the AWS IoT Greengrass command-line interface (CLI) to locally develop and debug applications on your device and the local debug console to help you visually debug applications.
        AWS IoT Greengrass ML Inference
        AWS IoT Greengrass ML Inference is a feature of AWS IoT Greengrass that makes it easy to perform machine learning inference locally on AWS IoT Greengrass devices using models that are built and trained in the cloud. This means you won’t incur data transfer costs or increased latency for applications that use machine learning inference. To learn more about the ML Inference feature, click here.
        
        Stream Manager for AWS IoT Greengrass
        You can use AWS IoT Greengrass to collect, process, and export data streams from IoT devices and manage the life cycle of that data on the device to minimize development time. AWS IoT Greengrass provides a standard mechanism to process data streams, manage local data-retention policies, and transmit device data to AWS cloud services such as Amazon Simple Storage Service (Amazon S3), Amazon Kinesis, AWS IoT Core, and AWS IoT Analytics.
        AWS IoT Greengrass components
        AWS IoT Greengrass provides prebuilt components for common use cases so you can discover and import, configure, and deploy applications and services at the edge without the need to understand different device protocols, manage credentials, or interact with external APIs. You can also create your own components or simply reuse common business logic from one AWS IoT Greengrass device to another.  
        
        AWS IoT Greengrass is modular. You can add or remove prebuilt software components based on your IoT use case, and your device CPU and memory resources. For example, you can choose to include prebuilt AWS IoT Greengrass components such as stream manager only when you need to process data streams with your application, or machine learning components only when you want to perform machine learning inference locally on your devices. To find available AWS IoT Greengrass components, view our documentation.
        
        Greengrass Software Catalog
        Greengrass Software Catalog is a collection of AWS IoT Greengrass components developed by the Greengrass community. Instead of developing device components for each required capability, you can now easily install, use, and modify components from a list of prebuilt software components on GitHub to kickstart your IoT edge application.
        
        For example, for a security monitoring solution, you can use the Amazon Kinesis Video Streams (KVS) component to ingest audio and video streams from Real Time Streaming Protocol (RTSP) cameras connected to a AWS IoT Greengrass Core device. The data can then be streamed to a local monitoring platform or sent to the cloud. Alternatively, for real-time analytics and local operations monitoring, you can use the InfluxDB and Grafana components to locally process and visualize data from IoT sensors and edge devices. Since these components are a reference implementation of common patterns, please ensure that you appropriately review and test any functionality before deploying it to your production environments. To get started, visit the Greengrass Software Catalog on GitHub.
        Manage IoT applications at scale
        AWS IoT Greengrass makes it easy to remotely deploy and manage device software on millions of devices. You can organize your devices in groups and deploy and manage device software and configuration to a subset of devices or to all devices at once. AWS IoT thing groups allow you to group multiple AWS IoT Greengrass devices, view deployment history, and start or stop deployments.
        Over the air updates
        AWS IoT Greengrass provides the ability to update the AWS IoT Greengrass Core software on AWS IoT Greengrass devices. You can use the AWS IoT Greengrass console, APIs, or command-line interface to update the version of AWS IoT Greengrass Cores or components running on your devices in order to deploy security updates, bug fixes, and new AWS IoT Greengrass features.
        
        Security & hardware integrations
        Hardware ecosystem
        AWS has created an ever-expanding selection of industry leading IoT silicon vendors, device manufacturers, and gateway partners who have integrated AWS IoT Greengrass into their software and hardware offerings. These partners help you move quickly from ideation to prototype to deployment. To learn more about AWS IoT Greengrass-enabled devices, visit the AWS Partner Device Catalog.
        
        AWS IoT Greengrass Secrets Manager
        AWS IoT Greengrass Secrets Manager allows you to securely store, access, rotate, and manage secrets—credentials, keys, endpoints, and configurations—at the edge. With AWS IoT Greengrass components integration, if an AWS IoT Greengrass component needs a secret to authenticate with an application or service, you can select and deploy a secret to the AWS IoT Greengrass Core as part of the component configuration. For example, you can use AWS IoT Greengrass Secrets Manager to configure credentials for private Docker container registries.
        Hardware Security Integration
        AWS IoT Greengrass offers customers the option to store their device private key on a hardware secure element. You can store sensitive device information at the edge with AWS IoT Greengrass Secrets Manager and encrypt your secrets using private keys for root of trust security. For a list of eligible hardware partners, visit the AWS Partner Device Catalog.
        
        AWS IoT Device Tester for AWS IoT Greengrass
        AWS IoT Device Tester for AWS IoT Greengrass is a test automation tool that helps you validate if your device meets the software and hardware requirements to run AWS IoT Greengrass. It supports configuration and dependency checks and end-to-end tests to validate if a device can support specific AWS IoT Greengrass features such as Machine Learning Inference. Additionally, hardware partners can download signed qualification reports from Device Tester and submit these reports to AWS Partner Central to qualify and list devices in the AWS Partner Device Catalog.
        
        To learn more and get started, visit the Device Tester technical documentation.</p>
  </details>
    <details>
        <summary>Machine Larning</summary>
        <p>Amazon Comprehend Features

            Amazon Comprehend is a natural language processing (NLP) service that uses machine learning to discover insights from text. Amazon Comprehend provides Custom Entity Recognition, Custom Classification, Key phrase Extraction, Sentiment Analysis, Entity Recognition, and more APIs so you can easily integrate natural language processing into your applications. You simply call the Amazon Comprehend APIs in your application and provide the location of the source document or text. The APIs will output entities, key phrases, sentiment, and language in a JSON format, which you can use in your application.
            Custom Entity Recognition
            Custom Entity Recognition allows you to customize Amazon Comprehend to identify terms that are specific to your domain. Using AutoML, Comprehend will learn from a small set of examples (for example, a list of policy numbers, claim numbers, or SSN), and then train a private, custom model to recognize these terms such as claim numbers in any other block of text within PDFs, plain text, or Microsoft Word documents – no machine learning required. Refer to this documentation page for more details. 
            
            Custom Classification
            The Custom Classification API enables you to easily build custom text classification models using your business-specific labels without learning ML. For example, your customer support organization can use Custom Classification to automatically categorize inbound requests by problem type based on how the customer has described the issue.  With your custom model, it is easy to moderate website comments, triage customer feedback, and organize workgroup documents. Refer to this documentation page for more details.
            Entity Recognition
            The Entity Recognition API returns the named entities ("People," "Places," "Locations," etc.) that are automatically categorized based on the provided text. Refer to this documentation page for more details.
            
            
            
            
            
            
            
            Sentiment Analysis
            The Sentiment Analysis API returns the overall sentiment of a text (Positive, Negative, Neutral, or Mixed). Refer to this documentation page for more details. 
            
            
            Targeted Sentiment
            Targeted Sentiment provides more granular sentiment insights by identifying the sentiment (positive, negative, neutral, or mixed) towards entities within text. Refer to this documentation page for more details.
            
            PII Identification and Redaction
            Use Amazon Comprehend ML capabilities to detect and redact personally identifiable information (PII) in customer emails, support tickets, product reviews, social media, and more. No ML experience required. For example, you can analyze support tickets and knowledge articles to detect PII entities and redact the text before you index the documents in the search solution. After that, search solutions are free of PII entities in documents. Redacting PII entities helps you protect privacy and comply with local laws and regulations. Refer to this documentation page for more details.
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            Keyphrase Extraction
            The Keyphrase Extraction API returns the key phrases or talking points and a confidence score to support that this is a key phrase. Refer to this documentation page for more details.
            
            
            
            
            
            
            
            Events Detection
            Comprehend Events lets you extract the event structure from a document, distilling pages of text down to easily processed data for consumption by your AI applications or graph visualization tools. This API allows you to answer who-what-when-where questions over large document sets, at scale and without prior NLP experience. Use Comprehend Events to extract granular details about real-world events and associated entities expressed in unstructured text. Refer to this documentation page for more details. 
            Language Detection
            The Language Detection API automatically identifies text written in over 100 languages and returns the dominant language with a confidence score to support that a language is dominant. Refer to this documentation page for more details.
            
            
            Syntax Analysis
            The Amazon Comprehend Syntax API enables customers to analyze text using tokenization and Parts of Speech (PoS), and identify word boundaries and labels like nouns and adjectives within the text. Refer to this documentation page for more details.
            
            
            
            
            Topic Modeling
            Topic Modeling identifies relevant terms or topics from a collection of documents stored in Amazon S3. It will identify the most common topics in the collection and organize them in groups and then map which documents belong to which topic. Refer to this documentation page for more details.
            Multiple language support
            Amazon Comprehend can perform text analysis on German, English, Spanish, Italian,
            Portuguese, French, Japanese, Korean, Hindi, Arabic, Chinese (simplified), Chinese (traditional) text. To build applications in other languages, customers can use Amazon Translate to convert the text into a language supported by Comprehend and then use Comprehend to perform text analysis. For more details on language support, see the documentation page.</p> 
    </details>
   <details>
    <summary>Networking & Content Delivery</summary>
    <p>Amazon API Gateway Features

        Amazon API Gateway is a fully managed service that makes it easy for developers to publish, maintain, monitor, secure, and operate APIs at any scale. It's a pay-as-you-go service that takes care of all of the undifferentiated heavy lifting involved in securely and reliably running APIs at scale.
        
        With the proliferation of mobile devices and the rise of the Internet of Things (IoT), it is increasingly common to make backend systems and data accessible to applications through APIs. Because so many applications use these APIs and communities of developers rely on them, an increasing amount of time and effort is spent on API development and API management. To make it easy for you to use these APIs, API Gateway can generate client SDKs for a number of languages, including JavaScript, iOS, and Android.
        Support for RESTful APIs and WebSocket APIs
        With API Gateway, you can create RESTful APIs using either HTTP APIs or REST APIs. HTTP APIs are the best way to build APIs that do not require API management features. HTTP APIs are optimized for serverless workloads and HTTP backends—they offer up to 71% cost savings and 60% latency reduction compared to REST APIs from API Gateway. For workloads that require API proxy functionality and API management features in a single solution, such as usage plans and API keys, API Gateway offers REST APIs. To see a side-by-side comparison of supported features for HTTP APIs and REST APIs, visit our documentation. To build real-time two-way communication applications, such as chat apps and streaming dashboards, use WebSocket APIs. To learn more about RESTful APIs and WebSocket APIs from API Gateway, visit our FAQ page.
        Private integrations with AWS ELB & AWS Cloud Map
        With API Gateway, you can route requests to private resources in your VPC. Using HTTP APIs, you can build APIs for services behind private ALBs, private NLBs, and IP-based services registered in AWS Cloud Map, such as ECS tasks.
        Resiliency
        API Gateway helps you manage traffic to your backend systems by allowing you to set throttling rules based on the number of requests per second for each HTTP method in your APIs. API Gateway handles any level of traffic received by an API, so you are free to focus on your business logic and services rather than maintaining infrastructure. If you’re using REST APIs, you can also set up a cache with customizable keys and time-to-live in seconds for your API data to avoid hitting your backend services for each request.
        Easy API Creation and Deployment
        With API Gateway, you can quickly and easily create a custom API to your code running in AWS Lambda and then call the Lambda code from your API. API Gateway can execute AWS Lambda code in your account, start AWS Step Functions state machines, or make calls to AWS Elastic Beanstalk, Amazon EC2, or web services outside of AWS with publicly accessible HTTP endpoints. Using the API Gateway console, you can define your REST API and its associated resources and methods, manage your API lifecycle, generate your client SDKs, and view API metrics.
        API Operations Monitoring
        After an API is deployed and in use, API Gateway provides you with a dashboard to visually monitor calls to the services. The API Gateway console is integrated with Amazon CloudWatch, so you get backend performance metrics such as API calls, latency, and error rates. Because API Gateway uses CloudWatch to record monitoring information, you can set up custom alarms on API Gateway APIs. API Gateway can also log API execution errors to CloudWatch Logs to make debugging easier.
        AWS Authorization
        To authorize and verify API requests to AWS services, API Gateway can help you leverage signature version 4 for REST APIs and WebSocket APIs. Using signature version 4 authentication, you can use AWS Identity and Access Management (IAM) and access policies to authorize access to your APIs and all your other AWS resources. You can also use AWS Lambda functions to verify and authorize bearer tokens such as JWT tokens or SAML assertions.
        API Keys for Third-Party Developers
        If you’re using REST APIs, API Gateway helps you manage the ecosystem of third-party developers accessing your APIs. You can create API keys on API Gateway, set fine-grained access permissions on each API key, and distribute them to third-party developers to access your APIs. You can also define plans that set throttling and request quota limits for each individual API key. The use of API keys is completely optional and must be enabled on a per-method level.
        SDK Generation
        If you’re using REST APIs, API Gateway can generate client SDKs for a number of platforms which you can use to quickly test new APIs from your applications and distribute SDKs to third-party developers. The generated SDKs handle API keys and sign requests using AWS credentials. API Gateway can generate client SDKs for Java, JavaScript, Java for Android, Objective-C or Swift for iOS, and Ruby. You can use AWS CLI to generate and download an SDK of an API for a supported platform by calling the get-sdk command.
        API Lifecycle Management
        If you're using REST APIs, API Gateway lets you run multiple versions of the same API simultaneously so that applications can continue to call previous API versions even after the latest versions are published. API Gateway also helps you manage multiple release stages for each API version, such as alpha, beta, and production. Each API stage can be configured to interact with different backend endpoints based on your API setup. Specific stages and versions of an API can be associated with a custom domain name and managed through API Gateway. Stage and version management allow you to easily test new API versions that enhance or add new functionality to earlier API releases, and ensures backward-compatibility as user communities transition to adopt the latest release.</p>
   </details>
   <details>
    <summary>Security , Identity , & Compliance</summary>
    <p>Amazon GuardDuty Features

        Overview
        Amazon GuardDuty is a threat detection service that continuously monitors for malicious activity and unauthorized behavior to protect your AWS accounts, Amazon Elastic Compute Cloud (EC2) workloads, container applications, Amazon Aurora databases, and data stored in Amazon Simple Storage Service (S3). GuardDuty combines machine learning, anomaly detection, network monitoring, and malicious file discovery, using both AWS and industry-leading third-party sources to help protect workloads and data on AWS. GuardDuty is capable of analyzing tens of billions of events across multiple AWS data sources, such as AWS CloudTrail event logs, Amazon Virtual Private Cloud (VPC) Flow Logs, Amazon Elastic Kubernetes Service (EKS) audit and system-level logs, and DNS query logs.
        Amazon GuardDuty identifies unusual activity within your accounts, analyzes the security relevance of the activity, and gives the context in which it was invoked. This allows a responder to determine if they should spend time on further investigation. GuardDuty findings are assigned a severity, and actions can be automated by integrating with AWS Security Hub, Amazon EventBridge, AWS Lambda, and AWS Step Functions. Amazon Detective is also tightly integrated with GuardDuty, so you can perform deeper forensic and root cause investigation.
        Accurate, account-level threat detection
        Amazon GuardDuty gives you accurate threat detection of compromised accounts, which can be difficult to detect quickly if you are not continuously monitoring factors in near real-time. GuardDuty can detect signs of account compromise, such as AWS resource access from an unusual geo-location at an atypical time of day. For programmatic AWS accounts, GuardDuty checks for unusual application programming interface (API) calls, such as attempts to obscure account activity by disabling CloudTrail logging or taking snapshots of a database from a malicious IP address.
        Continuous monitoring across AWS accounts without added cost and complexity
        Amazon GuardDuty continuously monitors and analyzes your AWS account and workload event data found in AWS CloudTrail, VPC Flow Logs, and DNS Logs. There is no additional security software or infrastructure to deploy and maintain. By associating your AWS accounts together, you can aggregate threat detection instead of working on an account-by-account basis. In addition, you do not have to collect, analyze, and correlate large volumes of AWS data from multiple accounts. Focus on how to respond quickly, how to keep your organization secure, and continuing to scale and innovate on AWS.
        Threat detections developed and optimized for the cloud
        Amazon GuardDuty helps you access built-in detection techniques developed and optimized for the cloud. AWS Security continuously maintains and improves these detection algorithms. The primary detection categories include:
        Reconnaissance: Activity suggesting reconnaissance by an attacker, such as unusual API activity, suspicious database login attempts, intra-VPC port scanning, unusual failed login request patterns, or unblocked port probing from a known bad IP.
        Instance compromise: Activity indicating an instance compromise, such as cryptocurrency mining, backdoor command and control (C&C) activity, malware using domain generation algorithms (DGA), outbound denial of service activity, unusually high network traffic volume, unusual network protocols, outbound instance communication with a known malicious IP, temporary Amazon EC2 credentials used by an external IP address, and data exfiltration using DNS.
        Account compromise: Common patterns indicative of account compromise include API calls from an unusual geolocation or anonymizing proxy, attempts to disable AWS CloudTrail logging, changes that weaken the account password policy, unusual instance or infrastructure launches, infrastructure deployments in an unusual region, credential theft, suspicious database login activity, and API calls from known malicious IP addresses.
        Bucket compromise: Activity indicating a bucket compromise, such as suspicious data access patterns indicating credential misuse, unusual Amazon S3 API activity from a remote host, unauthorized S3 access from known malicious IP addresses, and API calls to retrieve data in S3 buckets from a user with no prior history of accessing the bucket or invoked from an unusual location. Amazon GuardDuty continuously monitors and analyzes AWS CloudTrail S3 data events (e.g. GetObject, ListObjects, DeleteObject) to detect suspicious activity across all of your Amazon S3 buckets.
        Here is a full list of GuardDuty finding types.
        GuardDuty offers these advanced detections using machine learning and anomaly detection to identify previously difficult to find threats, such as unusual API call patterns or malicious AWS Identity and Access Management (IAM) user behavior. GuardDuty also has integrated threat intelligence, which includes lists of malicious domains or IP addresses from AWS Security and industry-leading third-party security partners, including Proofpoint and CrowdStrike.
        
        GuardDuty gives you an alternative to building in-house solutions, maintaining complex custom rules, or developing your own threat intelligence of known malicious IP addresses. GuardDuty removes the undifferentiated heavy lifting and unnecessary complexity of monitoring and protecting your AWS accounts and workloads.
        Threat severity levels for efficient prioritization
        Amazon GuardDuty provides three severity levels (Low, Medium, and High) to help customers prioritize their response to potential threats. A “Low” severity level indicates suspicious or malicious activity that was blocked before it compromised your resource. A “Medium” severity level indicates suspicious activity. For example, a large amount of traffic returned to a remote host hiding behind the Tor network, or activity that deviates from normally observed behavior. A “High” severity level indicates that the resource in question (e.g. an Amazon EC2 instance or a set of IAM user credentials) is compromised and is actively being used for unauthorized purposes.
        Threat response and remediation automation
        Amazon GuardDuty offers HTTPS APIs, command-line interface (CLI) tools, and Amazon CloudWatch Events to support automated security responses to security findings. For example, you can automate the response workflow by using CloudWatch Events as an event source to invoke an AWS Lambda function.
        Highly available threat detection
        Amazon GuardDuty is designed to automatically manage resource utilization based on the overall activity levels within your AWS accounts, workloads, and data stored in Amazon S3. GuardDuty adds detection capacity only when necessary, and reduces utilization when capacity is no longer needed. You now have a cost-effective architecture that maintains the security processing power you need while minimizing expenses. You only pay for the detection capacity you use, when you use it. GuardDuty gives you security at scale, no matter your size.
        One-step deployment with no additional software or infrastructure to deploy and manage
        With one action in the AWS Management Console or a single API call, you can activate Amazon GuardDuty on a single account. With a few more steps in the console, you can activate GuardDuty across multiple accounts. Amazon GuardDuty supports multiple accounts through AWS Organizations integration as well as natively within GuardDuty. Once turned on, GuardDuty immediately starts analyzing continuous streams of account and network activity in near real time and at scale. There are no additional security software, sensors, or network appliances to deploy or manage. Threat intelligence is pre-integrated into the service and are continuously updated and maintained.</p>
   </details>
   <details>
    <summary>serverless</summary>
    <p>AWS Lambda Features
        AWS Lambda is a serverless compute service that runs your code in response to events and automatically manages the underlying compute resources for you. These events may include changes in state or an update, such as a user placing an item in a shopping cart on an ecommerce website. You can use AWS Lambda to extend other AWS services with custom logic, or create your own backend services that operate at AWS scale, performance, and security. AWS Lambda automatically runs code in response to multiple events, such as HTTP requests via Amazon API Gateway, modifications to objects in Amazon Simple Storage Service (Amazon S3) buckets, table updates in Amazon DynamoDB, and state transitions in AWS Step Functions.
        
        Lambda runs your code on high availability compute infrastructure and performs all the administration of your compute resources. This includes server and operating system maintenance, capacity provisioning and automatic scaling, code and security patch deployment, and code monitoring and logging. All you need to do is supply the code.
        Key product features
        Extend other AWS services with custom logic
        AWS Lambda allows you to add custom logic to AWS resources such as Amazon S3 buckets and Amazon DynamoDB tables, so you can easily apply compute to data as it enters or moves through the cloud.
        It is easy to get started with AWS Lambda. First, you create your function by uploading your code (or building it right in the Lambda console) and choosing the memory, timeout period, and AWS Identity and Access Management (IAM) role. Then, you specify the AWS resource to trigger the function, which can be a particular Amazon S3 bucket, Amazon DynamoDB table, or  Amazon Kinesis stream. When the resource changes, Lambda will run your function, launching and managing the compute resources as needed to keep up with incoming requests.
        
        Build custom backend services
        You can use AWS Lambda to create new backend application services triggered on demand using the Lambda application programming interface (API) or custom API endpoints built using Amazon API Gateway. Lambda processes custom events instead of servicing these on the client, helping you avoid client platform variations, reduce battery drain, and enable easier updates.
        Bring your own code
        With AWS Lambda, there are no new languages, tools, or frameworks to learn. You can use any third- party library, even native ones. You can also package any code (frameworks, SDKs, libraries, and more) as a Lambda Layer, and manage and share them easily across multiple functions. Lambda natively supports Java, Go, PowerShell, Node.js, C#, Python, and Ruby code, and provides a Runtime API allowing you to use any additional programming languages to author your functions.
        Completely automated administration
        AWS Lambda manages all the infrastructure to run your code on highly available, fault tolerant infrastructure, freeing you to focus on building differentiated backend services. With Lambda, you never have to update the underlying operating system (OS) when a patch is released, or worry about resizing or adding new servers as your usage grows. AWS Lambda seamlessly deploys your code, handles all the administration, maintenance, and security patches, and provides built-in logging and monitoring through Amazon CloudWatch.
        Built-in fault tolerance
        AWS Lambda maintains compute capacity across multiple Availability Zones (AZs) in each AWS Region to help protect your code against individual machine or data center facility failures. Both AWS Lambda and the functions running on the service deliver predictable and reliable operational performance. AWS Lambda is designed to provide high availability for both the service itself and the functions it operates. There are no maintenance windows or scheduled downtimes.
        Package and deploy functions as container images
        AWS Lambda supports function packaging and deployment as container images, making it easy for customers to build Lambda-based applications using familiar container image tooling, workflows, and dependencies. Customers also benefit from Lambda’s operational simplicity, automatic scaling with sub-second startup times, high availability, pay-for-use billing model, and native integrations with over 200 AWS services and software-as-a service (SaaS) applications. Enterprise customers can use a consistent set of tools with both their Lambda and containerized applications, simplifying central governance requirements such as security scanning and image signing.
        Automatic scaling
        AWS Lambda invokes your code only when needed, and automatically scales to support the rate of incoming requests without any manual configuration. There is no limit to the number of requests your code can handle. AWS Lambda typically starts running your code within milliseconds of an event. Since Lambda scales automatically, the performance remains consistently high as the event frequency increases. Since your code is stateless, Lambda can start as many instances as needed without lengthy deployment and configuration delays.
        Connect to relational databases
        Use Amazon RDS Proxy to take advantage of fully managed connection pools for relational databases. RDS Proxy efficiently manages thousands of concurrent connections to relational databases, making it easy to build highly scalable, secure Lambda-based serverless applications interacting with relational databases. Currently, RDS Proxy offers support for MySQL and Aurora. You can use RDS Proxy for your serverless applications through the Amazon RDS console or AWS Lambda console.
        Fine-grained control over performance
        Provisioned Concurrency gives you greater control over your serverless application performance. When turned on, Provisioned Concurrency keeps functions initialized and hyper-ready to respond in double-digit milliseconds. Provisioned Concurrency is ideal for any AWS Lambda application requiring greater control over function start time. Easily configure and adjust the concurrency your application needs. Scale up, down, or turn it off completely depending on demand. Take advantage of Provisioned Concurrency to achieve consistent performance for latency-sensitive applications without changing your code or managing compute resources.
        Connect to shared file systems
        With Amazon Elastic File System (EFS) for AWS Lambda, you can securely read, write, and persist large volumes of data at low latency, at any scale. You don't need to write code and download data to temporary storage in order to process it. This saves time and simplifies the code, so you can focus on your business logic. EFS for Lambda is ideal for a range of use cases including processing or backing up large data amounts, and loading large reference files or models. You can also share files between serverless instances or container-based applications, and even run machine learning (ML) inference by using EFS for AWS Lambda.
        Run code in response to Amazon CloudFront requests
        With Lambda@Edge, AWS Lambda can run your code across AWS locations globally in response to Amazon CloudFront events, such as content requests to or from origin servers and viewers. This makes it easier to deliver richer, more personalized content to your end users with lower latency. 
        Orchestrate multiple functions
        Build AWS Step Functions workflows to coordinate multiple AWS Lambda functions for complex or long-running tasks. Step Functions lets you define workflows that trigger a collection of Lambda functions using sequential, parallel, branching, and error-handling steps. With Step Functions and Lambda, you can build stateful, long-running processes for applications and backends.
        Integrated security model
        AWS Lambda's built-in software development kit (SDK) integrates with AWS Identity and Access Management (IAM) to ensure secure code access to other AWS services. AWS Lambda runs your code within an Amazon Virtual Private Cloud (VPC) by default. Optionally, you can configure AWS Lambda resource access behind your own VPC in order to leverage custom security groups and network access control lists. This provides secure Lambda function access to your resources within a VPC. AWS Lambda is SOC, HIPAA, PCI, and ISO-compliant. For the latest in Lambda certification and compliance readiness, please see the full services in scope.
        
        Trust and integrity controls
        Code Signing for AWS Lambda allows you to verify that only unaltered code published by approved developers is deployed in your Lambda functions. You simply create digitally signed code artifacts and configure your Lambda functions to verify the signatures at deployment. This increases the speed and agility of your application development, even within large teams, while enforcing high security standards.
        Only pay for what you use
        With AWS Lambda, you pay for execution duration rather than server unit. When using Lambda functions, you only pay for requests served and the compute time required to run your code. Billing is metered in increments of one millisecond, enabling easy and cost-effective automatic scaling from a few requests per day to thousands per second. With Provisioned Concurrency, you pay for the amount of concurrency you configure and the duration that you configure it. When Provisioned Concurrency is enabled and your function is executed, you also pay for requests and execution duration. To learn more about pricing, please visit AWS Lambda Pricing.
        Flexible resource model
        Choose the amount of memory you want to allocate to your functions, and AWS Lambda allocates proportional CPU power, network bandwidth, and disk input/output (I/O).
        Integrate Lambda with your favorite operational tools
        AWS Lambda extensions enable easy integration with your favorite monitoring, observability, security, and governance tools. Lambda invokes your function in an execution environment, which provides a secure and isolated runtime where your function code is executed. Lambda extensions run within Lambda’s execution environment, alongside your function code. Lambda extensions can use the AWS Lambda Telemetry API to capture fine grained diagnostic information, such as logs, metrics, and traces, directly from Lambda, and send them to a destination of your choice. You can also use extensions to integrate your preferred security agents with Lambda, all with no operational overhead and minimal impact to your function performance.
        Achieve up to 34% better price performance with functions powered by Graviton2
        AWS Lambda functions running on Graviton2, using an Arm-based processor architecture designed by AWS, deliver up to 34% better price performance compared to functions running on x86 processors. This applies to a variety of serverless workloads, such as web and mobile backends, data, and media processing. With lower latency, up to 19% better performance, a 20% lower cost, and the highest power-efficiency currently available at AWS, Graviton2 functions can be used to power mission critical serverless applications.
        </p>
   </details>
   <details>
    <summary>Storage</summary>
    <p>Amazon EBS features

        Amazon EBS allows you to create storage volumes and attach them to Amazon EC2 instances. Once attached, you can create a file system on top of these volumes, run a database, or use them in any other way you would use block storage. Amazon EBS volumes are placed in a specific Availability Zone where they are automatically replicated to protect you from the failure of a single component. All EBS volume types offer durable snapshot capabilities and are designed for high availability.
        
        Amazon EBS provides a range of options that allow you to optimize storage performance and cost for your workload. These options are divided into two major categories: SSD-backed storage for transactional workloads, such as databases and boot volumes (performance depends primarily on IOPS), and HDD-backed storage for throughput intensive workloads, such as MapReduce and log processing (performance depends primarily on MB/s).
        
        Our highest performance io2 Block Express volume enables the first SAN in the Cloud. Block Express is a next-generation storage server architecture that provides the highest block storage performance without the cost or hassle of having to procure, scale, and maintain expensive on-premises SANs. With io2 volumes running on Block Express, you can achieve sub-millisecond latency and provision a single io2 volume with up to 256,000 IOPS, 4,000 MB/second throughput, and 64 TB of capacity—a 4x increase in performance, throughput, and capacity for existing io2 volumes. io2 Block Express volumes are ideal for the largest, most I/O-intensive, mission-critical deployments of Oracle databases, SAP HANA, Microsoft SQL Server, InterSystems database, and SAS Analytics.
        SSD-backed volumes include the highest performance Provisioned IOPS SSD (io2 and io1) for latency-sensitive transactional workloads and General Purpose SSD (gp3 and gp2) that balance price and performance for a wide variety of transactional data. HDD-backed volumes include Throughput Optimized HDD (st1) for frequently accessed, throughput intensive workloads and the lowest cost Cold HDD (sc1) for less frequently accessed data.
        
        Elastic Volumes is a feature of Amazon EBS that allows you to dynamically increase capacity, tune performance, and change the type of live volumes with no downtime or performance impact. This allows you to easily right-size your deployment and adapt to performance changes.
        Amazon EBS volume types
        The following table shows use cases and performance characteristics of current generation EBS volumes:
        Solid State Drives (SSD)
         
        Volume Type
        
        EBS Provisioned IOPS SSD (io2 Block Express)
        
        EBS Provisioned IOPS SSD (io2)
        EBS Provisioned IOPS SSD (io1)	EBS General Purpose SSD (gp3)	EBS General Purpose SSD (gp2)*
        Short Description
        
        Highest performance SSD volume designed for business-critical latency-sensitive transactional workloads	Highest performance and highest durability SSD volume designed for latency-sensitive transactional workloads	
        Highest performance SSD volume designed for latency-sensitive transactional workloads
        
        Lowest cost SSD volume that balances price performance for a wide variety of transactional workloads
        
        General Purpose SSD volume that balances price performance for a wide variety of transactional workloads
        
        Durability	
        99.999%
        
        99.999%	99.8% - 99.9% durability
        99.8% - 99.9% durability
        
        99.8% - 99.9% durability
        Use Cases
        
        Largest, most I/O intensive, mission critical deployments of NoSQL and relational databases such as Oracle, SAP HANA, Microsoft SQL Server, and SAS Analytics
        
        I/O-intensive NoSQL and relational databases	
        I/O-intensive NoSQL and relational databases
        
        Virtual desktops, medium sized single instance databases such as Microsoft SQL Server and Oracle, latency sensitive interactive applications, boot volumes, and dev/test environments
        
        Virtual desktops, medium sized single instance databases such as Microsoft SQL Server and Oracle, latency sensitive interactive applications, boot volumes, and dev/test environments
        
        API Name
        
        io2
        
        io2	
        io1
        
        gp3
        
        gp2
        
        Volume Size
        
        4 GB – 64 TB
        
        4 GB – 16 TB	
        4 GB - 16 TB
        
        1 GB - 16 TB
        
        1 GB - 16 TB
        
        Max IOPS**/Volume
        
        256,000
        
        64,000	
        64,000
        
        16,000
        
        16,000
        
        Max Throughput***/Volume
        
        4,000 MB/s
        
        1,000 MB/s	
        1,000 MB/s
        
        1,000 MB/s
        
        250 MB/s
        
        Max IOPS/Instance
        
        350,000
        
        160,000**	
        350,000
        
        260,000
        
        260,000
        
        Max Throughput/Instance
        
        10,000 MB/s
        
        4,750 MB/s**	
        10,000 MB/s
        
        10,000 MB/s
        
        7,500 MB/s
        
        Latency	sub-millisecond	single digit millisecond	single digit millisecond	single digit millisecond	single digit millisecond
        Price
        
        $0.125/GB-month
        
        $0.065/provisioned IOPS-month up to 32,000 IOPS
        
        $0.046/provisioned IOPS-month from 32,001 to 64,000
        
        $0.032/provisioned IOPS-month for greater than 64,000 IOPS
        
        $0.125/GB-month
        
        $0.065/provisioned IOPS-month
        
        $0.08/GB-month
        
        3,000 IOPS free and $0.005/provisioned IOPS-month over 3,000;
        
        125 MB/s free and $0.04/provisioned MB/s-month over 125
        
        $0.10/GB-month
        
        Dominant Performance Attribute
        
        IOPS, throughput, latency, capacity, and volume durability	IOPS and volume durability	
        IOPS
        
        IOPS	
        IOPS
        
         
        *Default volume type
        **Not currently supported by the EC2 instances which support io2 Block Express
        ***Volume throughput is calculated as MB = 1024^2 bytes
        Hard Disk Drives (HDD)	 
             Throughput Optimized HDD (st1)	Cold HDD (sc1)
        Short Description
        
        Low cost HDD volume designed for frequently accessed, throughput intensive workloads	Lowest cost HDD volume designed for less frequently accessed workloads
        Durability	99.8% - 99.9% durability
        99.8% - 99.9% durability
        Use Cases
        
        Big data, data warehouses, log processing	Colder data requiring fewer scans per day
        API Name
        
        st1	sc1
        Volume Size
        
        125 GB - 16 TB	125 GB - 16 TB
        Max IOPS**/Volume
        
        500	250
        Max Throughput***/Volume
        
        500 MB/s	250 MB/s
        Max Throughput/Instance
        
        10,000 MB/s	7,500 MB/s
        Price
        
        $0.045/GB-month	$0.015/GB-month
        Dominant Performance Attribute
        
        MB/s	MB/s
         
        Looking for EBS Magnetic? See the Previous Generation Volumes page.
        * st1/sc1 based on 1 MB I/O size
        ** volume throughput is calculated as MB = 1024^2 bytes
        
        SSD-backed volumes (IOPS-intensive)
        Provisioned IOPS SSD (io2 Block Express, io2 & io1) volumes
        Provisioned IOPS SSD volumes are designed to deliver a maximum of 256,000 IOPS, 4,000 MB/s of throughput, and 64 TiB in size per volume1. io2 Block Express is the latest generation of the Provisioned IOPS SSD volumes that delivers 4x higher throughput, IOPS, and capacity than regular io2 volumes, along with sub-millisecond latency – at the same price as io2. io2 Block Express provides highest block storage performance for the largest, most I/O- intensive, mission-critical deployments of Oracle, Microsoft SQL Server, SAP HANA, and SAS Analytics. To start using io2 Block Express volumes, simply attach new or existing io2 volumes to an EC2 instance type that runs on the new EBS Block Express architecture. For the EC2 instances that support io2 Block Express, see io2 Block Express volumes.
        
        When attached to EBS-optimized EC2 instances, io1 and io2 volumes are designed to achieve single-digit millisecond latencies, as well as deliver the provisioned performance 99.9% of the time. This makes io2 volumes ideal for performance intensive, business-critical applications that will benefit from higher uptime. Like io1 volumes, io2 and io2 Block Express volumes support Multi-Attach, which allows customers to attach an io2 volume to up to sixteen Nitro-based EC2 instances within the same Availability Zone. In addition, Fast Snapshot Restore and Elastic Volumes are also supported in all Provisioned IOPS SSD volumes. For more details on pricing, please visit the pricing page. For more information about instance types that can be launched as EBS-optimized instances, see Amazon EC2 Instance Types. For more information about Amazon EBS performance guidelines, see Increasing EBS Performance. Learn more »
        1 To go beyond the current io2 per volume limit of 64,000 IOPS, 1,000 MB/s throughput, or 16 TiB size, attach the io2 volume to an EC2 instance that runs on the new EBS Block Express architecture. For the EC2 instances that support io2 Block Express, see io2 Block Express volumes.
        
        General purpose SSD (gp3 and gp2) volumes
        General-purpose volumes are backed by solid-state drives (SSDs) and are suitable for a broad range of transactional workloads, virtual desktops, medium sized single instance databases, latency sensitive interactive applications, dev/test environments, and boot volumes. Amazon gp3 volumes are the latest generation of general-purpose SSD-based EBS volumes that enable customers to provision performance independent of storage capacity, while providing up to 20% lower pricing per GB than existing gp2 volumes. The new gp3 volumes deliver a baseline performance of 3,000 IOPS and 125 MB/s at any volume size. Customers looking for higher performance can scale up to 16,000 IOPS and 1,000 MB/s for an additional fee. Both gp3 and gp2 volumes are designed to offer single-digit millisecond latency and deliver the provisioned performance 99% of the time. If you need a greater number of IOPS than gp3 can provide, or if you have a workload where low latency is critical or you need better performance consistency, we recommend that you use io2 volumes. To maximize the performance of gp3, we recommend using EBS-optimized EC2 instances.
        
        HDD-backed volumes (MB/s-intensive)
        Throughput optimized HDD (st1) volumes
        ST1 is backed by hard disk drives (HDDs) and is ideal for frequently accessed, throughput intensive workloads with large datasets and large I/O sizes, such as MapReduce, Kafka, log processing, data warehouse, and ETL workloads. These volumes deliver performance in terms of throughput, measured in MB/s, and include the ability to burst up to 250 MB/s per TB, with a baseline throughput of 40 MB/s per TB and a maximum throughput of 500 MB/s per volume. ST1 is designed to deliver the expected throughput performance 99% of the time and has enough I/O credits to support a full-volume scan at the burst rate. To maximize the performance of st1, we recommend using EBS-optimized EC2 instances.
        Cold HDD (sc1) volumes
        SC1 is backed by hard disk drives (HDDs) and provides the lowest cost per GB of all EBS volume types. It is ideal for less frequently accessed workloads with large, cold datasets. Similar to st1, sc1 provides a burst model: these volumes can burst up to 80 MB/s per TB, with a baseline throughput of 12 MB/s per TB and a maximum throughput of 250 MB/s per volume. For infrequently accessed data, sc1 provides extremely inexpensive storage. SC1 is designed to deliver the expected throughput performance 99% of the time and has enough I/O credits to support a full-volume scan at the burst rate. To maximize the performance of sc1, we recommend using EBS-optimized EC2 instances.
        Amazon data lifecycle manager for EBS snapshots
        Data Lifecycle Manager for EBS snapshots provides a simple, automated way to back up data stored on EBS volumes by ensuring that EBS snapshots are created and deleted on a custom schedule. You no longer need to use scripts or other tools to comply with data backup and retention policies specific to your organization or industry.
        
        With lifecycle management, you can be sure that snapshots are cleaned up regularly and keep costs under control. Simply tag your EBS volumes and start creating Lifecycle policies for creation and management of backups. Use CloudWatch Events to monitor your policies and ensure that your backups are being created successfully.
        Amazon EBS Elastic Volumes
        Elastic Volumes is a feature that allows you to easily adapt your volumes as the needs of your applications change. Elastic Volumes allows you to dynamically increase capacity, tune performance, and change the type of any new or existing current generation volume with no downtime or performance impact. Easily right-size your deployment and adapt to performance changes.
        
        Simply create a volume with the capacity and performance needed today knowing you have the ability to modify your volume configuration in the future, saving hours of planning cycles.
        
        By using Amazon CloudWatch with AWS Lambda, you can automate volume changes to meet the changing needs of your applications.
        
        The Elastic Volumes feature makes it easier to adapt your resources to changing application demands, giving you confidence that you can make modifications in the future as your business needs change.
        Amazon EBS Snapshots
        Amazon EBS provides the ability to save point-in-time snapshots of your volumes to Amazon S3. Amazon EBS Snapshots are stored incrementally: only the blocks that have changed after your last snapshot are saved, and you are billed only for the changed blocks. If you have a device with 100 GB of data but only 5 GB has changed after your last snapshot, a subsequent snapshot consumes only 5 additional GB and you are billed only for the additional 5 GB of snapshot storage, even though both the earlier and later snapshots appear complete.
        
        When you delete a snapshot, you remove only the data not needed by any other snapshot. All active snapshots contain all the information needed to restore the volume to the instant at which that snapshot was taken. The time to restore changed data to the working volume is the same for all snapshots.
        
        Snapshots can be used to instantiate multiple new volumes, expand the size of a volume, or move volumes across Availability Zones. When a new volume is created, you may choose to create it based on an existing Amazon EBS snapshot. In that scenario, the new volume begins as an exact replica of the snapshot.
        
        The following are key features of Amazon EBS Snapshots:
        
        Direct read access of EBS Snapshots - Customers can use EBS direct APIs for Snapshots to read data off snapshots and identify differences between two EBS snapshots without needing to create EBS volumes and EC2 instances. EBS direct APIs for Snapshots enable backup partners to track incremental changes on EBS volumes more efficiently, providing faster backup times and more granular recovery point objectives (RPOs) to customers at a lower cost. For more information, see the EBS direct APIs for Snapshots technical documentation and pricing page.
        Creating EBS snapshots from any block storage - Using EBS direct APIs, you can create EBS snapshots directly from any block storage data, regardless of where it resides, including data on-premises, and quickly recover into EBS volumes. This allows you to meet your disaster recovery objectives in AWS at lower costs. For more information, see the EBS direct APIs for Snapshots technical documentation and pricing page.
        Immediate access to Amazon EBS volume data - After a volume is created from a snapshot, there is no need to wait for all of the data to transfer from Amazon S3 to your Amazon EBS volume before your attached instance can start accessing the volume. Amazon EBS Snapshots implement lazy loading, so that you can begin using them right away.
        Instant full performance on EBS volumes restored from snapshots - For an additional hourly charge, you can enable Fast Snapshot Restore (FSR) capability for low latency access to data restored from snapshots. EBS volumes restored from FSR-enabled snapshots instantly receive their full performance. For more information, see the FSR technical documentation and pricing page.
        Resizing Amazon EBS volumes - There are two methods that can be used to resize an Amazon EBS volume. If you create a new volume based on a snapshot, you can specify a larger size for the new volume. With the Elastic Volumes feature you can dynamically grow live volumes without the use of snapshots. Make certain that your file system and application supports resizing a device.
        Sharing Amazon EBS Snapshots - Amazon EBS Snapshots’ shareability makes it easy for you to share data with your co-workers or others in the AWS community. Authorized users can create their own Amazon EBS volumes based on your Amazon EBS shared snapshots; your original snapshot remains intact. If you choose, you can also make your data available publicly to all AWS users. For more information about how to share snapshots, see Modifying Snapshot Permissions.
        Copying Amazon EBS Snapshots across AWS regions - Amazon EBS’s ability to copy snapshots across AWS regions makes it easier to leverage multiple AWS regions for geographical expansion, data center migration and disaster recovery. You can copy any snapshot accessible to you: snapshots you created; snapshots shared with you; and snapshots from the AWS Marketplace, VM Import/Export, and AWS Storage Gateway. For more information, see Copying an Amazon EBS Snapshot.
        EBS Snapshots Archive - EBS Snapshots Archive is a lower storage cost tier which stores a full copy of your point-in-time EBS Snapshots. Unlike an EBS Snapshot of a volume which is incremental, a snapshot archive is “full” since it contains all the blocks written into the volume at the moment the snapshot was taken. To recreate a volume from EBS Snapshots Archive, you restore the EBS Snapshot to the standard tier, and then create an EBS volume from the restored snapshot.
        Instant full performance on EBS volumes restored from snapshots - For an additional hourly charge, you can enable Fast Snapshot Restore (FSR) capability for low latency access to data restored from snapshots. You can enable FSR on snapshots you own or those shared with you. EBS volumes restored from FSR-enabled snapshots instantly receive their full performance. For more information, see the FSR technical documentation and pricing page.
        
        Amazon EBS-Optimized instances
        For an additional low, hourly fee, customers can launch certain Amazon EC2 instance types as EBS-optimized instances. EBS-optimized instances enable EC2 instances to fully use the IOPS provisioned on an EBS volume.
        
        EBS-optimized instances deliver dedicated throughput between Amazon EC2 and Amazon EBS, with options between 500 and 80,000 Megabits per second (Mbps) depending on the instance type used. The dedicated throughput minimizes contention between Amazon EBS I/O and other traffic from your EC2 instance, providing the best performance for your EBS volumes.
        
        EBS-optimized instances are designed for use with all Amazon EBS volume types.
        
        For more information about the instance types that can be launched as EBS-Optimized instances, see Amazon EC2 Instance Types.
        Amazon EBS availability and durability
        Amazon EBS volumes are designed to be highly available, reliable, and durable. At no additional charge to you, Amazon EBS volume data is replicated across multiple servers in an Availability Zone to prevent the loss of data from the failure of any single component. For more details, see the Amazon EBS Service Level Agreement.
        Amazon EBS offers a higher durability volume (io2), that is designed to provide 99.999% durability with an annual failure rate (AFR) of 0.001%, where failure refers to a complete or partial loss of the volume. For example, if you have 100,000 EBS io2 volumes running for 1 year, you should expect only one io2 volume to experience a failure. This makes io2 ideal for business-critical applications such as SAP HANA, Oracle, Microsoft SQL Server and IBM DB2 that will benefit from higher uptime. io2 volumes are 2000 times more reliable than typical commodity disk drives, which fail with an AFR of around 2%. All other Amazon EBS volumes are designed to provided 99.8%-99.9% durability with an AFR of between 0.1% - 0.2%,
        
        EBS also supports a snapshot feature, which is a good way to take point-in-time backups of your data. To learn more about Amazon EBS Snapshots and how to take point-in time backups of your volumes please visit here.
        Amazon EBS encryption and AWS Identity and Access Management
        Amazon EBS encryption offers seamless encryption of EBS data volumes, boot volumes and snapshots, eliminating the need to build and manage a secure key management infrastructure. EBS encryption enables data at rest security by encrypting your data volumes, boot volumes and snapshots using Amazon-managed keys or keys you create and manage using the AWS Key Management Service (KMS). In addition, the encryption occurs on the servers that host EC2 instances, providing encryption of data as it moves between EC2 instances and EBS data and boot volumes. For more information, see Amazon EBS encryption in the Amazon EC2 User Guide.
        
        Access to Amazon EBS volumes is integrated with AWS Identity and Access Management (IAM). IAM enables access control to your Amazon EBS volumes. For more information, see AWS Identity and Access Management.
        on this page GB = 1024^3 bytes
        Amazon EBS Multi-Attach
        Customers can enable Multi-Attach on an EBS Provisioned IOPS io2 or io1 volume to allow a volume to be concurrently attached to up to sixteen Nitro-based EC2 instances within the same Availability Zone. Multi-Attach makes it easier to achieve higher application availability for applications that manage storage consistency from multiple writers. Each attached instance has full read and write permission to the shared volume. Applications using Multi-Attach need to provide IO fencing for storage consistency. There is no additional fee to enable Multi-Attach.
        
        To learn more, see Multi-Attach technical documentation.
        
        Amazon EBS Torn Write Prevention
        Torn Write Prevention (TWP) ensures that full 16KiB write operations are persisted to the block storage. With this feature, customers can turn off the double write operation that MySQL and MariaDB databases perform for increased database write throughput. These customers can increase the number of transactions processed per second (TPS) by up to 30% without having to over-provision or scale up their clusters, thereby reducing storage cost. By eliminating the second write operation, TWP decreases the write latency and variability in the number of TPS by up to 50%, enabling customers to improve their Service Level Agreement (SLA) without compromising the resiliency of their workloads.
        TWP supports all Amazon EBS volumes attached to EC2 Nitro-based instances. To learn more, see Torn Write Prevention technical documentation.
        </p>
   </details>

</fieldset>

</body>
</html>